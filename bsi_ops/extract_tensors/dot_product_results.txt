Layer 1 - Q shape: torch.Size([1, 482, 768]), K shape: torch.Size([1, 482, 768]), V shape: torch.Size([1, 482, 768])
Q size: 1480848 bytes
K size: 1480848 bytes
Precision of the K tensor: 32 bits
Data Type of the K tensor: torch.float32 
Precision of the K tensor: 32 bits
Data Type of the K tensor: torch.float32 
BERT normalized Q and K dot product::: bsi: 95846.423848, normal: 96035.1328125, percentage error: 0.1965019851922989%
Time taken for BSI operation: 0.0013257999999999998
 Time taken for torch operation: 0.00046234130859375

Layer 2 - Q shape: torch.Size([1, 482, 768]), K shape: torch.Size([1, 482, 768]), V shape: torch.Size([1, 482, 768])
Q size: 1480848 bytes
K size: 1480848 bytes
Precision of the K tensor: 32 bits
Data Type of the K tensor: torch.float32 
Precision of the K tensor: 32 bits
Data Type of the K tensor: torch.float32 
BERT normalized Q and K dot product::: bsi: 86109.464424, normal: 86287.7578125, percentage error: 0.20663055777549744%
Time taken for BSI operation: 0.0013362000000000003
 Time taken for torch operation: 8.296966552734375e-05

Layer 3 - Q shape: torch.Size([1, 482, 768]), K shape: torch.Size([1, 482, 768]), V shape: torch.Size([1, 482, 768])
Q size: 1480848 bytes
K size: 1480848 bytes
Precision of the K tensor: 32 bits
Data Type of the K tensor: torch.float32 
Precision of the K tensor: 32 bits
Data Type of the K tensor: torch.float32 
BERT normalized Q and K dot product::: bsi: 84226.619289, normal: 84403.25, percentage error: 0.20927253365516663%
Time taken for BSI operation: 0.0013557999999999999
 Time taken for torch operation: 7.519721984863281e-05

Layer 4 - Q shape: torch.Size([1, 482, 768]), K shape: torch.Size([1, 482, 768]), V shape: torch.Size([1, 482, 768])
Q size: 1480848 bytes
K size: 1480848 bytes
Precision of the K tensor: 32 bits
Data Type of the K tensor: torch.float32 
Precision of the K tensor: 32 bits
Data Type of the K tensor: torch.float32 
BERT normalized Q and K dot product::: bsi: 95170.6947, normal: 95358.75, percentage error: 0.19720758497714996%
Time taken for BSI operation: 0.0013491999999999998
 Time taken for torch operation: 8.392333984375e-05

Layer 5 - Q shape: torch.Size([1, 482, 768]), K shape: torch.Size([1, 482, 768]), V shape: torch.Size([1, 482, 768])
Q size: 1480848 bytes
K size: 1480848 bytes
Precision of the K tensor: 32 bits
Data Type of the K tensor: torch.float32 
Precision of the K tensor: 32 bits
Data Type of the K tensor: torch.float32 
BERT normalized Q and K dot product::: bsi: 112379.069038, normal: 112583.2421875, percentage error: 0.1813519299030304%
Time taken for BSI operation: 0.0013769999999999998
 Time taken for torch operation: 8.282661437988281e-05

Layer 6 - Q shape: torch.Size([1, 482, 768]), K shape: torch.Size([1, 482, 768]), V shape: torch.Size([1, 482, 768])
Q size: 1480848 bytes
K size: 1480848 bytes
Precision of the K tensor: 32 bits
Data Type of the K tensor: torch.float32 
Precision of the K tensor: 32 bits
Data Type of the K tensor: torch.float32 
BERT normalized Q and K dot product::: bsi: 98674.439477, normal: 98865.875, percentage error: 0.1936335414648056%
Time taken for BSI operation: 0.00133
 Time taken for torch operation: 7.700920104980469e-05

Layer 7 - Q shape: torch.Size([1, 482, 768]), K shape: torch.Size([1, 482, 768]), V shape: torch.Size([1, 482, 768])
Q size: 1480848 bytes
K size: 1480848 bytes
Precision of the K tensor: 32 bits
Data Type of the K tensor: torch.float32 
Precision of the K tensor: 32 bits
Data Type of the K tensor: torch.float32 
BERT normalized Q and K dot product::: bsi: 94181.392665, normal: 94369.2578125, percentage error: 0.19907666742801666%
Time taken for BSI operation: 0.00137
 Time taken for torch operation: 8.525848388671876e-05

Layer 8 - Q shape: torch.Size([1, 482, 768]), K shape: torch.Size([1, 482, 768]), V shape: torch.Size([1, 482, 768])
Q size: 1480848 bytes
K size: 1480848 bytes
Precision of the K tensor: 32 bits
Data Type of the K tensor: torch.float32 
Precision of the K tensor: 32 bits
Data Type of the K tensor: torch.float32 
BERT normalized Q and K dot product::: bsi: 104543.742119, normal: 104740.78125, percentage error: 0.18812067806720734%
Time taken for BSI operation: 0.0013804
 Time taken for torch operation: 9.88006591796875e-05

Layer 9 - Q shape: torch.Size([1, 482, 768]), K shape: torch.Size([1, 482, 768]), V shape: torch.Size([1, 482, 768])
Q size: 1480848 bytes
K size: 1480848 bytes
Precision of the K tensor: 32 bits
Data Type of the K tensor: torch.float32 
Precision of the K tensor: 32 bits
Data Type of the K tensor: torch.float32 
BERT normalized Q and K dot product::: bsi: 87071.374338, normal: 87251.734375, percentage error: 0.2067115157842636%
Time taken for BSI operation: 0.0013906
 Time taken for torch operation: 8.039474487304687e-05

Layer 10 - Q shape: torch.Size([1, 482, 768]), K shape: torch.Size([1, 482, 768]), V shape: torch.Size([1, 482, 768])
Q size: 1480848 bytes
K size: 1480848 bytes
Precision of the K tensor: 32 bits
Data Type of the K tensor: torch.float32 
Precision of the K tensor: 32 bits
Data Type of the K tensor: torch.float32 
BERT normalized Q and K dot product::: bsi: 97208.818447, normal: 97399.9765625, percentage error: 0.1962590217590332%
Time taken for BSI operation: 0.0013395999999999998
 Time taken for torch operation: 7.805824279785156e-05

Layer 11 - Q shape: torch.Size([1, 482, 768]), K shape: torch.Size([1, 482, 768]), V shape: torch.Size([1, 482, 768])
Q size: 1480848 bytes
K size: 1480848 bytes
Precision of the K tensor: 32 bits
Data Type of the K tensor: torch.float32 
Precision of the K tensor: 32 bits
Data Type of the K tensor: torch.float32 
BERT normalized Q and K dot product::: bsi: 96218.935997, normal: 96408.296875, percentage error: 0.19641397893428802%
Time taken for BSI operation: 0.0013130000000000004
 Time taken for torch operation: 6.732940673828124e-05

Layer 12 - Q shape: torch.Size([1, 482, 768]), K shape: torch.Size([1, 482, 768]), V shape: torch.Size([1, 482, 768])
Q size: 1480848 bytes
K size: 1480848 bytes
Precision of the K tensor: 32 bits
Data Type of the K tensor: torch.float32 
Precision of the K tensor: 32 bits
Data Type of the K tensor: torch.float32 
BERT normalized Q and K dot product::: bsi: 92796.589552, normal: 92982.6640625, percentage error: 0.20012131333351135%
Time taken for BSI operation: 0.0014026
 Time taken for torch operation: 8.440017700195312e-05


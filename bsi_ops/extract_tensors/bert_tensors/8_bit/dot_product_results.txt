Layer 1 - Q shape: torch.Size([1, 512, 1024]), K shape: torch.Size([1, 512, 1024]), V shape: torch.Size([1, 512, 1024])
Q size: 2097296 bytes
K size: 2097296 bytes
BSI Q size: 1008 bytes
BSI K size: 1008 bytes
Precision of the K tensor: 32 bits
Data Type of the K tensor: torch.float32 
Precision of the K tensor: 32 bits
Data Type of the K tensor: torch.float32 
BERT normalized Q and K dot product::: bsi: 137199.40625, normal: 138249.59375, percentage error: 0.7596315145492554%
Time taken for BSI operation: 0.001238
 Time taken for torch operation: 0.00020060539245605468

Layer 2 - Q shape: torch.Size([1, 512, 1024]), K shape: torch.Size([1, 512, 1024]), V shape: torch.Size([1, 512, 1024])
Q size: 2097296 bytes
K size: 2097296 bytes
BSI Q size: 1008 bytes
BSI K size: 1008 bytes
Precision of the K tensor: 32 bits
Data Type of the K tensor: torch.float32 
Precision of the K tensor: 32 bits
Data Type of the K tensor: torch.float32 
BERT normalized Q and K dot product::: bsi: 123699.92805480957, normal: 124700.0625, percentage error: 0.8020306825637817%
Time taken for BSI operation: 0.0012188000000000001
 Time taken for torch operation: 0.00013489723205566405

Layer 3 - Q shape: torch.Size([1, 512, 1024]), K shape: torch.Size([1, 512, 1024]), V shape: torch.Size([1, 512, 1024])
Q size: 2097296 bytes
K size: 2097296 bytes
BSI Q size: 1008 bytes
BSI K size: 1008 bytes
Precision of the K tensor: 32 bits
Data Type of the K tensor: torch.float32 
Precision of the K tensor: 32 bits
Data Type of the K tensor: torch.float32 
BERT normalized Q and K dot product::: bsi: 124043.93801879883, normal: 125046.0703125, percentage error: 0.8014109134674072%
Time taken for BSI operation: 0.0012105999999999998
 Time taken for torch operation: 0.00010433197021484376

Layer 4 - Q shape: torch.Size([1, 512, 1024]), K shape: torch.Size([1, 512, 1024]), V shape: torch.Size([1, 512, 1024])
Q size: 2097296 bytes
K size: 2097296 bytes
BSI Q size: 1008 bytes
BSI K size: 1008 bytes
Precision of the K tensor: 32 bits
Data Type of the K tensor: torch.float32 
Precision of the K tensor: 32 bits
Data Type of the K tensor: torch.float32 
BERT normalized Q and K dot product::: bsi: 136914.09982299805, normal: 137967.5, percentage error: 0.7635176777839661%
Time taken for BSI operation: 0.0013844000000000003
 Time taken for torch operation: 0.00011401176452636718

Layer 5 - Q shape: torch.Size([1, 512, 1024]), K shape: torch.Size([1, 512, 1024]), V shape: torch.Size([1, 512, 1024])
Q size: 2097296 bytes
K size: 2097296 bytes
BSI Q size: 1008 bytes
BSI K size: 1008 bytes
Precision of the K tensor: 32 bits
Data Type of the K tensor: torch.float32 
Precision of the K tensor: 32 bits
Data Type of the K tensor: torch.float32 
BERT normalized Q and K dot product::: bsi: 142861.1534576416, normal: 143936.8125, percentage error: 0.7473114132881165%
Time taken for BSI operation: 0.0012201999999999998
 Time taken for torch operation: 0.00010595321655273437

Layer 6 - Q shape: torch.Size([1, 512, 1024]), K shape: torch.Size([1, 512, 1024]), V shape: torch.Size([1, 512, 1024])
Q size: 2097296 bytes
K size: 2097296 bytes
BSI Q size: 1008 bytes
BSI K size: 1008 bytes
Precision of the K tensor: 32 bits
Data Type of the K tensor: torch.float32 
Precision of the K tensor: 32 bits
Data Type of the K tensor: torch.float32 
BERT normalized Q and K dot product::: bsi: 130334.39778137207, normal: 131357.875, percentage error: 0.7791512608528137%
Time taken for BSI operation: 0.0012452
 Time taken for torch operation: 0.00010614395141601562

Layer 7 - Q shape: torch.Size([1, 512, 1024]), K shape: torch.Size([1, 512, 1024]), V shape: torch.Size([1, 512, 1024])
Q size: 2097296 bytes
K size: 2097296 bytes
BSI Q size: 1008 bytes
BSI K size: 1008 bytes
Precision of the K tensor: 32 bits
Data Type of the K tensor: torch.float32 
Precision of the K tensor: 32 bits
Data Type of the K tensor: torch.float32 
BERT normalized Q and K dot product::: bsi: 131576.9966430664, normal: 132605.9375, percentage error: 0.7759361863136292%
Time taken for BSI operation: 0.0012439999999999999
 Time taken for torch operation: 0.00010685920715332031

Layer 8 - Q shape: torch.Size([1, 512, 1024]), K shape: torch.Size([1, 512, 1024]), V shape: torch.Size([1, 512, 1024])
Q size: 2097296 bytes
K size: 2097296 bytes
BSI Q size: 1008 bytes
BSI K size: 1008 bytes
Precision of the K tensor: 32 bits
Data Type of the K tensor: torch.float32 
Precision of the K tensor: 32 bits
Data Type of the K tensor: torch.float32 
BERT normalized Q and K dot product::: bsi: 117954.31300354004, normal: 118936.875, percentage error: 0.8261210322380066%
Time taken for BSI operation: 0.0013046
 Time taken for torch operation: 0.00011429786682128906

Layer 9 - Q shape: torch.Size([1, 512, 1024]), K shape: torch.Size([1, 512, 1024]), V shape: torch.Size([1, 512, 1024])
Q size: 2097296 bytes
K size: 2097296 bytes
BSI Q size: 1008 bytes
BSI K size: 1008 bytes
Precision of the K tensor: 32 bits
Data Type of the K tensor: torch.float32 
Precision of the K tensor: 32 bits
Data Type of the K tensor: torch.float32 
BERT normalized Q and K dot product::: bsi: 151026.20664978027, normal: 152130.234375, percentage error: 0.7257145643234253%
Time taken for BSI operation: 0.0012538
 Time taken for torch operation: 0.00011706352233886719

Layer 10 - Q shape: torch.Size([1, 512, 1024]), K shape: torch.Size([1, 512, 1024]), V shape: torch.Size([1, 512, 1024])
Q size: 2097296 bytes
K size: 2097296 bytes
BSI Q size: 1008 bytes
BSI K size: 1008 bytes
Precision of the K tensor: 32 bits
Data Type of the K tensor: torch.float32 
Precision of the K tensor: 32 bits
Data Type of the K tensor: torch.float32 
BERT normalized Q and K dot product::: bsi: 136443.01997375488, normal: 137491.09375, percentage error: 0.762287974357605%
Time taken for BSI operation: 0.0011987999999999999
 Time taken for torch operation: 0.00011801719665527344

Layer 11 - Q shape: torch.Size([1, 512, 1024]), K shape: torch.Size([1, 512, 1024]), V shape: torch.Size([1, 512, 1024])
Q size: 2097296 bytes
K size: 2097296 bytes
BSI Q size: 1008 bytes
BSI K size: 1008 bytes
Precision of the K tensor: 32 bits
Data Type of the K tensor: torch.float32 
Precision of the K tensor: 32 bits
Data Type of the K tensor: torch.float32 
BERT normalized Q and K dot product::: bsi: 130841.65075683594, normal: 131863.75, percentage error: 0.775119423866272%
Time taken for BSI operation: 0.001239
 Time taken for torch operation: 0.00011878013610839843

Layer 12 - Q shape: torch.Size([1, 512, 1024]), K shape: torch.Size([1, 512, 1024]), V shape: torch.Size([1, 512, 1024])
Q size: 2097296 bytes
K size: 2097296 bytes
BSI Q size: 1008 bytes
BSI K size: 1008 bytes
Precision of the K tensor: 32 bits
Data Type of the K tensor: torch.float32 
Precision of the K tensor: 32 bits
Data Type of the K tensor: torch.float32 
BERT normalized Q and K dot product::: bsi: 115830.52819824219, normal: 116794.53125, percentage error: 0.8253811001777649%
Time taken for BSI operation: 0.0012435999999999999
 Time taken for torch operation: 0.00010528564453125

Layer 13 - Q shape: torch.Size([1, 512, 1024]), K shape: torch.Size([1, 512, 1024]), V shape: torch.Size([1, 512, 1024])
Q size: 2097296 bytes
K size: 2097296 bytes
BSI Q size: 1008 bytes
BSI K size: 1008 bytes
Precision of the K tensor: 32 bits
Data Type of the K tensor: torch.float32 
Precision of the K tensor: 32 bits
Data Type of the K tensor: torch.float32 
BERT normalized Q and K dot product::: bsi: 133980.3716430664, normal: 135015.9375, percentage error: 0.7669928073883057%
Time taken for BSI operation: 0.0012121999999999999
 Time taken for torch operation: 0.00010781288146972656

Layer 14 - Q shape: torch.Size([1, 512, 1024]), K shape: torch.Size([1, 512, 1024]), V shape: torch.Size([1, 512, 1024])
Q size: 2097296 bytes
K size: 2097296 bytes
BSI Q size: 1008 bytes
BSI K size: 1008 bytes
Precision of the K tensor: 32 bits
Data Type of the K tensor: torch.float32 
Precision of the K tensor: 32 bits
Data Type of the K tensor: torch.float32 
BERT normalized Q and K dot product::: bsi: 126413.68934631348, normal: 127417.4921875, percentage error: 0.7878076434135437%
Time taken for BSI operation: 0.0012926
 Time taken for torch operation: 0.00010852813720703125

Layer 15 - Q shape: torch.Size([1, 512, 1024]), K shape: torch.Size([1, 512, 1024]), V shape: torch.Size([1, 512, 1024])
Q size: 2097296 bytes
K size: 2097296 bytes
BSI Q size: 1008 bytes
BSI K size: 1008 bytes
Precision of the K tensor: 32 bits
Data Type of the K tensor: torch.float32 
Precision of the K tensor: 32 bits
Data Type of the K tensor: torch.float32 
BERT normalized Q and K dot product::: bsi: 139589.54064941406, normal: 140644.25, percentage error: 0.749908447265625%
Time taken for BSI operation: 0.0012331999999999998
 Time taken for torch operation: 0.00010800361633300781

Layer 16 - Q shape: torch.Size([1, 512, 1024]), K shape: torch.Size([1, 512, 1024]), V shape: torch.Size([1, 512, 1024])
Q size: 2097296 bytes
K size: 2097296 bytes
BSI Q size: 1008 bytes
BSI K size: 1008 bytes
Precision of the K tensor: 32 bits
Data Type of the K tensor: torch.float32 
Precision of the K tensor: 32 bits
Data Type of the K tensor: torch.float32 
BERT normalized Q and K dot product::: bsi: 114326.98020935059, normal: 115284.046875, percentage error: 0.8301844596862793%
Time taken for BSI operation: 0.001271
 Time taken for torch operation: 0.00011205673217773438

Layer 17 - Q shape: torch.Size([1, 512, 1024]), K shape: torch.Size([1, 512, 1024]), V shape: torch.Size([1, 512, 1024])
Q size: 2097296 bytes
K size: 2097296 bytes
BSI Q size: 1008 bytes
BSI K size: 1008 bytes
Precision of the K tensor: 32 bits
Data Type of the K tensor: torch.float32 
Precision of the K tensor: 32 bits
Data Type of the K tensor: torch.float32 
BERT normalized Q and K dot product::: bsi: 127505.65190124512, normal: 128514.9453125, percentage error: 0.7853536605834961%
Time taken for BSI operation: 0.0012369999999999998
 Time taken for torch operation: 0.00012555122375488282

Layer 18 - Q shape: torch.Size([1, 512, 1024]), K shape: torch.Size([1, 512, 1024]), V shape: torch.Size([1, 512, 1024])
Q size: 2097296 bytes
K size: 2097296 bytes
BSI Q size: 1008 bytes
BSI K size: 1008 bytes
Precision of the K tensor: 32 bits
Data Type of the K tensor: torch.float32 
Precision of the K tensor: 32 bits
Data Type of the K tensor: torch.float32 
BERT normalized Q and K dot product::: bsi: 127049.24284362793, normal: 128056.109375, percentage error: 0.7862703204154968%
Time taken for BSI operation: 0.0012656
 Time taken for torch operation: 0.00011696815490722657

Layer 19 - Q shape: torch.Size([1, 512, 1024]), K shape: torch.Size([1, 512, 1024]), V shape: torch.Size([1, 512, 1024])
Q size: 2097296 bytes
K size: 2097296 bytes
BSI Q size: 1008 bytes
BSI K size: 1008 bytes
Precision of the K tensor: 32 bits
Data Type of the K tensor: torch.float32 
Precision of the K tensor: 32 bits
Data Type of the K tensor: torch.float32 
BERT normalized Q and K dot product::: bsi: 122468.44952392578, normal: 123459.7265625, percentage error: 0.8029123544692993%
Time taken for BSI operation: 0.0012309999999999999
 Time taken for torch operation: 0.00010485649108886719

Layer 20 - Q shape: torch.Size([1, 512, 1024]), K shape: torch.Size([1, 512, 1024]), V shape: torch.Size([1, 512, 1024])
Q size: 2097296 bytes
K size: 2097296 bytes
BSI Q size: 1008 bytes
BSI K size: 1008 bytes
Precision of the K tensor: 32 bits
Data Type of the K tensor: torch.float32 
Precision of the K tensor: 32 bits
Data Type of the K tensor: torch.float32 
BERT normalized Q and K dot product::: bsi: 134157.89862060547, normal: 135199.25, percentage error: 0.7702289819717407%
Time taken for BSI operation: 0.0012640000000000001
 Time taken for torch operation: 0.00012755393981933594

Layer 21 - Q shape: torch.Size([1, 512, 1024]), K shape: torch.Size([1, 512, 1024]), V shape: torch.Size([1, 512, 1024])
Q size: 2097296 bytes
K size: 2097296 bytes
BSI Q size: 1008 bytes
BSI K size: 1008 bytes
Precision of the K tensor: 32 bits
Data Type of the K tensor: torch.float32 
Precision of the K tensor: 32 bits
Data Type of the K tensor: torch.float32 
BERT normalized Q and K dot product::: bsi: 137019.60667419434, normal: 138070.1875, percentage error: 0.7609015107154846%
Time taken for BSI operation: 0.0011912
 Time taken for torch operation: 0.00011758804321289062

Layer 22 - Q shape: torch.Size([1, 512, 1024]), K shape: torch.Size([1, 512, 1024]), V shape: torch.Size([1, 512, 1024])
Q size: 2097296 bytes
K size: 2097296 bytes
BSI Q size: 1008 bytes
BSI K size: 1008 bytes
Precision of the K tensor: 32 bits
Data Type of the K tensor: torch.float32 
Precision of the K tensor: 32 bits
Data Type of the K tensor: torch.float32 
BERT normalized Q and K dot product::: bsi: 122094.08337402344, normal: 123089.734375, percentage error: 0.8088802099227905%
Time taken for BSI operation: 0.0013666
 Time taken for torch operation: 0.00013060569763183593

Layer 23 - Q shape: torch.Size([1, 512, 1024]), K shape: torch.Size([1, 512, 1024]), V shape: torch.Size([1, 512, 1024])
Q size: 2097296 bytes
K size: 2097296 bytes
BSI Q size: 1008 bytes
BSI K size: 1008 bytes
Precision of the K tensor: 32 bits
Data Type of the K tensor: torch.float32 
Precision of the K tensor: 32 bits
Data Type of the K tensor: torch.float32 
BERT normalized Q and K dot product::: bsi: 123569.71673583984, normal: 124567.421875, percentage error: 0.8009342551231384%
Time taken for BSI operation: 0.0012394
 Time taken for torch operation: 0.00011134147644042969

Layer 24 - Q shape: torch.Size([1, 512, 1024]), K shape: torch.Size([1, 512, 1024]), V shape: torch.Size([1, 512, 1024])
Q size: 2097296 bytes
K size: 2097296 bytes
BSI Q size: 1008 bytes
BSI K size: 1008 bytes
Precision of the K tensor: 32 bits
Data Type of the K tensor: torch.float32 
Precision of the K tensor: 32 bits
Data Type of the K tensor: torch.float32 
BERT normalized Q and K dot product::: bsi: 130233.46821594238, normal: 131258.4375, percentage error: 0.7808783650398254%
Time taken for BSI operation: 0.0012514000000000002
 Time taken for torch operation: 0.00010614395141601562

